{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install llama-index\n",
    "# !pip install openai\n",
    "# !pip install pypdf\n",
    "# !pip install --upgrade llama_index\n",
    "\n",
    "# # to use llama-index embeddings\n",
    "# !pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import os.path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response.pprint_utils import pprint_response, pprint, pprint_metadata, pprint_source_node\n",
    "\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core.retrievers import TreeRootRetriever\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your views here.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create your views here.\n",
    "load_dotenv()  # loads variables from .env into environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "client = openai.OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../Current Cybersecurity Law/'\n",
    "PERSIST_DIR = '../Vector_Storage_Context/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "# Open the PDF file in binary mode\n",
    "def read_pdf(file):\n",
    "    with open(file, 'rb') as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        # Get the total number of pages in the PDF\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "\n",
    "        pdf_text = \"\"\n",
    "\n",
    "        # Iterate through each page and extract text\n",
    "        for page_number in range(num_pages):\n",
    "            # Get a specific page\n",
    "            page = pdf_reader.pages[page_number]\n",
    "\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            pdf_text += text\n",
    "\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "def get_pdfs(root_folder):\n",
    "    pdf_files = []\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(foldername, filename))\n",
    "    return pdf_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_required_states(query):\n",
    "#     prompt = f'''Suppose I have legislation documents on all the states of United States, including federal and international documents.\\n\n",
    "#                 Here is a following query. \n",
    "#                 1) The query might want to look into only federal legislations. Then only mention \"Federal\" in your answer.\n",
    "#                 2) The query might want to look into only international legislations. Then only mention \"International\" in your answer.\n",
    "#                 3) The query might want to look into only state documents, then mentiona those state names.\n",
    "#                     If the query says compare between state X and Y, you should mention both state X and Y.\n",
    "#                     If the query says compare between state X and all other state with a condition,\n",
    "#                     you should mention state X and all other state that satisfies the condition.\n",
    "#                 4) If none of the above, then mention all the state names along with \"Federal\" and \"International\"\n",
    "                \n",
    "#                 Based on the folllowing query, which state documents, including federal and international, should I look into?\n",
    "#                 Think multiple time and do not miss out any state names.\n",
    "\n",
    "#                 Give me the state names in comma seperated line.\n",
    "#                 For example: Texas,Alabama,New York\n",
    "#                 Do not add any additional explanation. Only the state names in python list format.\n",
    "                \n",
    "#                 -------------------------------------------------------------\n",
    "#                 query:\n",
    "#                 {query} \n",
    "#                 -------------------------------------------------------------\n",
    "#                 '''\n",
    "        \n",
    "#     gpt_response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages= [\n",
    "#         {\n",
    "#             \"role\":\"system\",\n",
    "#             \"content\":'''You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\n",
    "#             You have a good knowledge about the states of the united states. Their geological position, political relationships, etc.'''\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\":\"user\",\n",
    "#             \"content\":prompt\n",
    "#         }\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "#     return gpt_response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_states(query):\n",
    "    prompt = f'''Suppose I have legislation documents on all the states of United States, along with federal and intenational level.\\n\n",
    "                Based on the folllowing query, which state documents should I look into?\\n\n",
    "\n",
    "                If the query says compare between state X and Y, you should mention both state X and Y.\n",
    "                If the query says compare between state X and all other state with a condition,\n",
    "                you should mention state X and all other state that satisfies the condition.\n",
    "                If the query does not mention any state, you should mention all the states that are in the U.S.\n",
    "                Think multiple time and do not miss out any state names.\n",
    "\n",
    "                Give me the state names in comma seperated line.\n",
    "                For example: Texas,Alabama,New York\n",
    "                Do not add any additional explanation. Only the state names in python list format.\n",
    "                \n",
    "                -------------------------------------------------------------\n",
    "                query:\n",
    "                {query} \n",
    "                -------------------------------------------------------------\n",
    "                '''\n",
    "        \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":'''You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\n",
    "            You have a good knowledge about the states of the united states. Their geological position, political relationships, etc.'''\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return gpt_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_query_engine(state_name):\n",
    "    print(f'Loading Index of {state_name}')\n",
    "    #  -- change these lines while using in the interface --\n",
    "    STATE_DATA_FOLDER = DATA_FOLDER + state_name + '/'\n",
    "    STATE_PERSIST_DIR = PERSIST_DIR + state_name + '/'\n",
    "    \n",
    "    index = None\n",
    "\n",
    "    if not os.path.exists(STATE_PERSIST_DIR):\n",
    "        # creating the index from the documents\n",
    "        print('Creating index of:',state_name)\n",
    "        os.mkdir(STATE_PERSIST_DIR)\n",
    "\n",
    "        pdf_files = get_pdfs(STATE_DATA_FOLDER)\n",
    "        documents = SimpleDirectoryReader(input_files=pdf_files).load_data()\n",
    "        index = VectorStoreIndex.from_documents(documents=documents)\n",
    "\n",
    "        # store it for later\n",
    "        index.storage_context.persist(persist_dir=STATE_PERSIST_DIR)\n",
    "    else:\n",
    "        # retrieving a storage context from already exixting contex and loading the index\n",
    "        storage_contex = StorageContext.from_defaults(persist_dir=STATE_PERSIST_DIR)\n",
    "        index = load_index_from_storage(storage_context=storage_contex)\n",
    "\n",
    "\n",
    "    retriever = VectorIndexRetriever(index=index, similarity_top_k=20)\n",
    "    postprocessor = SimilarityPostprocessor(similarity_cutoff=0.50)\n",
    "\n",
    "    query_engine = RetrieverQueryEngine(retriever=retriever, node_postprocessors=[postprocessor])\n",
    "    return query_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(data_folder):\n",
    "  dirs = os.listdir(data_folder)\n",
    "  return dirs\n",
    "\n",
    "def create_query_engines(states = None):\n",
    "  if states is None:\n",
    "    states = get_states(DATA_FOLDER)\n",
    "  query_engines = {}\n",
    "\n",
    "  for state in states:\n",
    "    query_engines[state] = create_state_query_engine(state)\n",
    "  \n",
    "  return query_engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Index of Alabama\n",
      "Loading Index of Alaska\n",
      "Loading Index of Arizona\n",
      "Loading Index of Arkansas\n",
      "Loading Index of California\n",
      "Loading Index of Colorado\n",
      "Loading Index of Connecticut\n",
      "Loading Index of Delaware\n",
      "Loading Index of District of Columbia\n",
      "Loading Index of Federal\n",
      "Loading Index of Florida\n",
      "Loading Index of Georgia\n",
      "Loading Index of Hawaii\n",
      "Loading Index of Idaho\n",
      "Loading Index of Illinois\n",
      "Loading Index of Indiana\n",
      "Loading Index of International\n",
      "Loading Index of Iowa\n",
      "Loading Index of Kansas\n",
      "Loading Index of Kentucky\n",
      "Loading Index of Louisiana\n",
      "Loading Index of Maine\n",
      "Loading Index of Maryland\n",
      "Loading Index of Massachusetts\n",
      "Loading Index of Michigan\n",
      "Loading Index of Minnesota\n",
      "Loading Index of Mississippi\n",
      "Loading Index of Missouri\n",
      "Loading Index of Montana\n",
      "Loading Index of Nebraska\n",
      "Loading Index of Nevada\n",
      "Loading Index of New Hampshire\n",
      "Loading Index of New Jersey\n",
      "Loading Index of New Mexico\n",
      "Loading Index of New York\n",
      "Loading Index of North Carolina\n",
      "Loading Index of North Dakota\n",
      "Loading Index of Ohio\n",
      "Loading Index of Oklahoma\n",
      "Loading Index of Oregon\n",
      "Loading Index of Pennsylvania\n",
      "Loading Index of Rhode Island\n",
      "Loading Index of South Carolina\n",
      "Loading Index of South Dakota\n",
      "Loading Index of Tennessee\n",
      "Loading Index of Texas\n",
      "Loading Index of Utah\n",
      "Loading Index of Vermont\n",
      "Loading Index of Virginia\n",
      "Loading Index of Washington\n",
      "Loading Index of West Virginia\n",
      "Loading Index of Wisconsin\n",
      "Loading Index of Wyoming\n"
     ]
    }
   ],
   "source": [
    "state_wise_query_engines = create_query_engines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(state_wise_query_engines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text):\n",
    "    \n",
    "    # Initialize the encoder for the specific model\n",
    "    encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    \n",
    "    # Encode the prompt to get the token count\n",
    "    tokenized_prompt = encoder.encode(text)\n",
    "    token_count = len(tokenized_prompt)\n",
    "    return token_count\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    text = f'''You have the following contexts and a Question. \n",
    "                Based on the information in the context, answer the question.\\n\n",
    "                -------------------------------------------------------------\n",
    "                Contexts:\n",
    "                {''}\n",
    "                -------------------------------------------------------------\n",
    "                Question: \n",
    "                {''}\n",
    "                -------------------------------------------------------------\n",
    "                Based on these contexts, answer the question. Try to use exact word from the context.\n",
    "                Answer as precisely as possible using the words from the context. Try to use all the information fom the context. \n",
    "                While answering, mention the legislation code first.\n",
    "                Try to preserve the paragrapg numberings also.\n",
    "                Do not add any informatio which is not present in the context.\n",
    "                Remove the word \"Trayce Hockstad\" from your response.\n",
    "                \n",
    "                \n",
    "                If I give you any context please mention the file name from where you are taking your information \n",
    "                at the end of your response as \"References\". Mention exact file paths as numbered list in seperate lines.\n",
    "                No need to mention the sources with the paragraphs. Just mention them at the end.\n",
    "\n",
    "                No need to mention refrence while aswering to greetings questions like Hi or Hello.\n",
    "\n",
    "                Here is a example of a response. Follow this response formate strictly:\n",
    "                Question:  What are the identidying document accordint to Alabama Legislations?\n",
    "                Response:\n",
    "                According to Code of Ala. § 8-27-2:\n",
    "                A “trade secret” is information that:\n",
    "                a. Is used or intended for use in a trade or business;\n",
    "                b. Is included or embodied in a formula, pattern, compilation, computer software,\n",
    "                drawing, device, method, technique, or process;\n",
    "                c. Is not publicly known and is not generally known in the trade or business of the person\n",
    "                asserting that it is a trade secret;\n",
    "                d. Cannot be readily ascertained or derived from publicly available information;\n",
    "                e. Is the subject of efforts that are reasonable under the circumstances to maintain its\n",
    "                secrecy; and\n",
    "                f. Has significant economic value.\n",
    "\n",
    "                Reference:\n",
    "                1) [file path]'''\n",
    "\n",
    "    print(count_tokens(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_wise_response(state,question,top_k=10, model = \"gpt-4o-mini\"):\n",
    "    prompt = question\n",
    "    query_engine = state_wise_query_engines[state]\n",
    "    response = query_engine.query(question)\n",
    "\n",
    "    context_1 = \"\"\n",
    "    context_2 = \"\"\n",
    "    refs = []\n",
    "    i = 0\n",
    "    l = []\n",
    "    for node in response.source_nodes:        \n",
    "        # context += f\"Context {i+1}: \\n\\n\"\n",
    "        refs.append(node.metadata['file_path'])\n",
    "        text = \"\"\n",
    "        text += f\"File name: {node.metadata['file_path']}\"\n",
    "        file_text = read_pdf(node.metadata['file_path'])\n",
    "        leg_code = file_text.split('\\n')[0]\n",
    "        text += \"Legislation code:\" + leg_code + '\\n'\n",
    "        text += file_text\n",
    "\n",
    "        token_count = count_tokens(context_1) + count_tokens(text) + count_tokens(question) + 450 + 1500\n",
    "        if token_count >= 16000 :\n",
    "            break\n",
    "\n",
    "        if 'insurance' in node.metadata['file_path'].lower():\n",
    "            context_2 += f\"Context {i+1}: \\n\\n\"\n",
    "            context_2 += text\n",
    "        else:\n",
    "            context_1 += f\"Context {i+1}: \\n\\n\"\n",
    "            context_1 += text\n",
    "\n",
    "        i += 1\n",
    "        if i == top_k:\n",
    "            break\n",
    "        \n",
    "\n",
    "    prompt = f'''You have the following contexts and a Question. \n",
    "                Based on the information in the context, answer the question.\\n\n",
    "                -------------------------------------------------------------\n",
    "                Contexts:\n",
    "                {context_1}\n",
    "                -------------------------------------------------------------\n",
    "                Question: \n",
    "                {question}\n",
    "                -------------------------------------------------------------\n",
    "                Based on these contexts, answer the question. Try to use exact word from the context.\n",
    "                Answer as precisely as possible using the words from the context. Try to use all the information fom the context. \n",
    "                While answering, mention the legislation code first.\n",
    "                Try to preserve the paragrapg numberings also.\n",
    "                Do not add any informatio which is not present in the context.\n",
    "                Remove the word \"Trayce Hockstad\" from your response.\n",
    "                \n",
    "                If I give you any context please mention the file name from where you are taking your information \n",
    "                at the end of your response as \"References\". Mention exact file paths as numbered list in seperate lines.\n",
    "                No need to mention the sources with the paragraphs. Just mention them at the end.\n",
    "\n",
    "                No need to mention refrence while aswering to greetings questions like Hi or Hello.\n",
    "\n",
    "                Here is a example of a response. Follow this response formate strictly:\n",
    "                According to Code of Ala. § 8-27-2:\n",
    "                A “trade secret” is information that:\n",
    "                a. Is used or intended for use in a trade or business;\n",
    "                b. Is included or embodied in a formula, pattern, compilation, computer software,\n",
    "                drawing, device, method, technique, or process;\n",
    "                c. Is not publicly known and is not generally known in the trade or business of the person\n",
    "                asserting that it is a trade secret;\n",
    "                d. Cannot be readily ascertained or derived from publicly available information;\n",
    "                e. Is the subject of efforts that are reasonable under the circumstances to maintain its\n",
    "                secrecy; and\n",
    "                f. Has significant economic value.\n",
    "\n",
    "                Reference:\n",
    "                1) [file path]\n",
    "                '''\n",
    "    # Question:  What are the identidying document accordint to Alabama Legislations?\n",
    "    # Response:\n",
    "        \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=model,\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1500,\n",
    "    )\n",
    "\n",
    "    ret_1 = str(gpt_response.choices[0].message.content).replace(\"\\n\",'<br>')\n",
    "\n",
    "    prompt = f'''You have the following contexts and a Question. \n",
    "                Based on the information in the context, answer the question.\\n\n",
    "                -------------------------------------------------------------\n",
    "                Contexts:\n",
    "                {context_2}\n",
    "                -------------------------------------------------------------\n",
    "                Question: \n",
    "                {question}\n",
    "                -------------------------------------------------------------\n",
    "                Based on these contexts, answer the question. Try to use exact word from the context.\n",
    "                Answer as precisely as possible using the words from the context. Try to use all the information fom the context. \n",
    "                While answering, mention the legislation code first.\n",
    "                Try to preserve the paragrapg numberings also.\n",
    "                Do not add any informatio which is not present in the context.\n",
    "                Remove the word \"Trayce Hockstad\" from your response.\n",
    "                If you do not have any answer, just give an empty response.\n",
    "                \n",
    "                If I give you any context please mention the file name from where you are taking your information \n",
    "                at the end of your response as \"References\". Mention exact file paths as numbered list in seperate lines.\n",
    "                No need to mention the sources with the paragraphs. Just mention them at the end.\n",
    "\n",
    "                No need to mention refrence while aswering to greetings questions like Hi or Hello.\n",
    "\n",
    "                Here is a example of a response. Follow this response formate strictly:\n",
    "                According to Code of Ala. § 8-27-2:\n",
    "                A “trade secret” is information that:\n",
    "                a. Is used or intended for use in a trade or business;\n",
    "                b. Is included or embodied in a formula, pattern, compilation, computer software,\n",
    "                drawing, device, method, technique, or process;\n",
    "                c. Is not publicly known and is not generally known in the trade or business of the person\n",
    "                asserting that it is a trade secret;\n",
    "                d. Cannot be readily ascertained or derived from publicly available information;\n",
    "                e. Is the subject of efforts that are reasonable under the circumstances to maintain its\n",
    "                secrecy; and\n",
    "                f. Has significant economic value.\n",
    "\n",
    "                Reference:\n",
    "                1) Current Cybersecurity Law\\Florida\\Information Technology\\Fla. Stat. _ 282.318.pdf\n",
    "                '''\n",
    "    # Question:  What are the identidying document accordint to Alabama Legislations?\n",
    "    # Response:\n",
    "        \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=model,\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1500,\n",
    "    )\n",
    "\n",
    "    ret_2 = str(gpt_response.choices[0].message.content).replace(\"\\n\",'<br>')\n",
    "\n",
    "    modified_ret = \"\"\n",
    "\n",
    "    if len(ret_2)>0:\n",
    "        modified_ret = ret_1 + \"\\nIndformation based on insurance documents:\\n\" + ret_2\n",
    "    else:\n",
    "        modified_ret = ret_1 \n",
    "\n",
    "    for ref in refs:\n",
    "        if ref in ret_1+ret_2:\n",
    "            modified_ref = modify_ref(ref)\n",
    "            modified_ret = modified_ret.replace(ref,modified_ref)\n",
    "    return modified_ret \n",
    "\n",
    "\n",
    "def modify_ref(ref):\n",
    "    pos = ref.find('Current')\n",
    "    rel_path = ref[pos:]\n",
    "    html = '<a href= \"static/'+str(rel_path)+'\" target=\"_blank\">'+ rel_path +'</a>'\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_state_wise_chunks(state,question,top_k=10):\n",
    "    prompt = question\n",
    "    query_engine = state_wise_query_engines[state]\n",
    "    response = query_engine.query(question)\n",
    "\n",
    "    i = 0\n",
    "    chunks = []\n",
    "    for i,node in enumerate(response.source_nodes):\n",
    "        chunks.append(node.text)\n",
    "        if i==4:\n",
    "            break\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_chunks(question,output_file):\n",
    "    required_states_set = set(get_required_states(question).split(','))\n",
    "\n",
    "    df = {}\n",
    "\n",
    "    required_states = []\n",
    "    for state in required_states_set:\n",
    "        required_states.append(state.strip())\n",
    "    \n",
    "    if \"\" in required_states:\n",
    "        required_states.remove(\"\")\n",
    "    chunks = []\n",
    "    for state in required_states:\n",
    "        chunks += get_state_wise_chunks(state, question)\n",
    "    \n",
    "    df['question'] = [question] + [\"\"]*(len(chunks)-1)\n",
    "    df['chunks'] = chunks\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accumulated_response(context, question, model=\"gpt-4o-mini\"):\n",
    "    print('--- Accumulating Response ----')\n",
    "        \n",
    "    prompt = f'''you have the following contexts.\\n\n",
    "                -------------------------------------------------------------\n",
    "                context:\n",
    "                {context}\n",
    "                -------------------------------------------------------------\n",
    "                Based on these contexts, answer the following query. Try to use exact word from the context.\n",
    "                Try to use all the information fom the context. Try to preserve the paragrapg numberings also.\n",
    "                Remove the word \"Trayce Hockstad\" from your response.\n",
    "                Query: {question}\n",
    "\n",
    "                No need to mention refrence while aswering to greetings questions like Hi or Hello.'''\n",
    "    \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=model,\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    ret = str(gpt_response.choices[0].message.content).replace(\"\\n\",'<br>')\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_checking(question, response, model = \"gpt-4o-mini\"):\n",
    "    prompt = f'''To answer a question about transportation legislation around different states of United States,\n",
    "                I have the following information about a particilar state. I am considering informations from different states to accumulate/compare them at the end to have a comprehensive answer.\n",
    "\n",
    "                Based on the question given below, check if the information given following is useful information or not. \n",
    "                Response \"Yes\" if and only if the information is useful, otherwise respond \"No\".\n",
    "                -------------------------------------------------------------\n",
    "                Question: {question}\n",
    "                -------------------------------------------------------------\n",
    "                Information: {response}\n",
    "                -------------------------------------------------------------\n",
    "                '''\n",
    "    \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=model,\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    ret = str(gpt_response.choices[0].message.content)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(question,response, model = \"gpt-4o-mini\"):\n",
    "    \n",
    "    prompt = f'''To answer the following question, summarise the given response.\\n\n",
    "                -------------------------------------------------------------\n",
    "                Question: {question}\n",
    "                -------------------------------------------------------------\n",
    "                Response: {response}\n",
    "                -------------------------------------------------------------\n",
    "                '''\n",
    "    \n",
    "    gpt_response = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=model,\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a helpful assisstant. Your name is TraCR AI. You were developed by TraCR. Your role is to help with Transportation Cybersecurity Legislations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    ret = str(gpt_response.choices[0].message.content).replace(\"\\n\",'<br>')\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query, only_accumulated_response = False, model = \"gpt-4o-mini\"):\n",
    "    required_states_set = set(get_required_states(query).split(','))\n",
    "\n",
    "    required_states = []\n",
    "    for state in required_states_set:\n",
    "        required_states.append(state.strip())\n",
    "    \n",
    "    if \"\" in required_states:\n",
    "        required_states.remove(\"\")\n",
    "    \n",
    "    response = \"\"\n",
    "    # response += \"Looking into the following states: <br>\"\n",
    "    # ind = 1\n",
    "    # for state in required_states:\n",
    "    #     response += str(ind) + '. ' + state + '<br>'\n",
    "    #     ind+=1\n",
    "\n",
    "    context = ''\n",
    "    # response += '<br>Responses based on different states:<br>'\n",
    "    state_wise_responses = {}\n",
    "    for state in required_states:\n",
    "        \n",
    "        if state in state_wise_query_engines:\n",
    "            print(f\"---------- Getting response for: {state} ---------------\")\n",
    "            state_wise_response = get_state_wise_response(state,query,model)\n",
    "            fact_check = fact_checking(query, state_wise_response,model)\n",
    "\n",
    "            if fact_check == \"No\":\n",
    "                print(\"Skipped!\")\n",
    "                response += state + ':<br>'\n",
    "                response += f'No documents found on this state.' +'<br>'\n",
    "                continue\n",
    "\n",
    "            context += state_wise_response + '\\n'\n",
    "            response += state + ': <br>'\n",
    "            response += state_wise_response +'<br>'\n",
    "            # for summarization\n",
    "            state_wise_responses[state] = state_wise_response\n",
    "            print(\"Included.\")\n",
    "        else:\n",
    "            print(f'{state} is not present ------------------------------')\n",
    "            response += state + ':<br>'\n",
    "            response += f'No documents found based on {state}.' +'<br>'\n",
    "\n",
    "    accumulated_response = \"\"   \n",
    "    if len(required_states)>1:\n",
    "        try:\n",
    "            accumulated_response = get_accumulated_response(context, query,model)\n",
    "        except Exception as e:\n",
    "            print(\"Maximum limit of context exceeded! Generating Summaries!\")\n",
    "            response = \"Looking into the following states: <br>\"\n",
    "            ind = 1\n",
    "            for state in required_states:\n",
    "                response += str(ind) + '. ' + state + '<br>'\n",
    "                ind+=1\n",
    "\n",
    "            context = ''\n",
    "\n",
    "\n",
    "            for state in required_states:\n",
    "                # response += state + ':<br>'\n",
    "                if state in state_wise_query_engines:\n",
    "                    print(f\"---------- Getting summary for: {state} ---------------\")\n",
    "                    context += get_summary(query, state_wise_response,model) + '\\n'\n",
    "                    response += state_wise_response +'<br>'\n",
    "                else:\n",
    "                    print(f'{state} is not present ------------------------------')\n",
    "                    response += f'No documents found based on {state}.' +'<br>'\n",
    "            \n",
    "            accumulated_response = get_accumulated_response(context, query, model)\n",
    "\n",
    "        # response += '<br>' + accumulated_response + '<br>'\n",
    "\n",
    "    if only_accumulated_response == True:\n",
    "        if len(required_states)>1:\n",
    "            return accumulated_response\n",
    "        else:\n",
    "            return response\n",
    "    else:\n",
    "        if len(required_states)>1:\n",
    "            return response + '<br>' + accumulated_response + '<br>'\n",
    "        else:\n",
    "            return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = [[],[],[],[],[],[],[],[],[],[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Response for all the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions from Trayce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 17\n",
      "2 of 17\n",
      "3 of 17\n",
      "4 of 17\n",
      "5 of 17\n",
      "6 of 17\n",
      "7 of 17\n",
      "8 of 17\n",
      "9 of 17\n",
      "10 of 17\n",
      "11 of 17\n",
      "12 of 17\n",
      "13 of 17\n",
      "14 of 17\n",
      "15 of 17\n",
      "16 of 17\n",
      "17 of 17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_df = pd.read_csv('../inputs/compiled_question_set _edited.csv')\n",
    "\n",
    "questions = in_df['question'][42:]\n",
    "\n",
    "for i,ques in enumerate(questions):\n",
    "    output_file = f'../outputs/similar chunks compiled_question_set _edited/Q{i+1}_similar_chunks.csv'\n",
    "    get_chunks(ques,output_file=output_file)\n",
    "    print(i+1,'of', len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Involving all the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def sol(INPUT_FILE, OUTPUT_FOLDER, response_per_question = 10, only_accumulated_response = False):\n",
    "    df = pd.read_csv(INPUT_FILE, encoding='utf-8')\n",
    "\n",
    "    START = 6\n",
    "    questions = df['question'][START:]\n",
    "    ids = df['id'][START:]\n",
    "    comments = list(df['comment'][START:])\n",
    "\n",
    "    for j, question in enumerate(questions):\n",
    "        if comments[j] == \"No\":\n",
    "            continue\n",
    "        new_df = {}\n",
    "        print(question)\n",
    "\n",
    "        new_df['id'] = [(j+1)]\n",
    "        new_df['question'] = [question]\n",
    "        for i in range(response_per_question):\n",
    "            print(i+1,end=\" \")\n",
    "            res = get_response(question,only_accumulated_response).replace('<br>','\\n')\n",
    "            res = res.split('Reference')[0].strip()\n",
    "            # print(res)\n",
    "            # print(j,i)\n",
    "            # input()\n",
    "            response[i].append(res)\n",
    "            new_df[f'response_{i+1}'] = [res]\n",
    "        print()\n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        new_df.to_csv(OUTPUT_FOLDER+f'Q{j+1}.csv',index = False)\n",
    "        print(f'{START+j+1} of {START+len(questions)} done')\n",
    "     \n",
    "sol('../inputs/compiled_question_set _edited.csv','../outputs/compiled_question_set _edited_responses/',1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not this cell\n",
    "response = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "\n",
    "def sol(INPUT_FILE, OUTPUT_FILE, response_per_question = 10, only_accumulated_response = False):\n",
    "    df = pd.read_csv(INPUT_FILE, encoding='utf-8')\n",
    "\n",
    "    questions = df['question']\n",
    "    comments = df['comment']\n",
    "\n",
    "\n",
    "    for j, question in enumerate(questions):\n",
    "        print(question)\n",
    "        if comments[j] == 'No':\n",
    "            print('Aborting question')\n",
    "            continue\n",
    "        for i in range(response_per_question):\n",
    "            res = get_response(question,only_accumulated_response).replace('<br>','\\n')\n",
    "            # res = res.split('Reference')[0].strip()\n",
    "            print(res)\n",
    "            # print(j,i)\n",
    "            # input()\n",
    "            response[i].append(res)\n",
    "        print('done')\n",
    "\n",
    "\n",
    "\n",
    "    df_out = pd.DataFrame()\n",
    "    df_out['question'] = questions\n",
    "    for i in range(response_per_question):\n",
    "        df_out[f'response_{i+1}'] = response[i]\n",
    "     \n",
    "    df_out.to_csv(OUTPUT_FILE,index=True)\n",
    "\n",
    "sol('../inputs/compiled_question_set _edited.csv','../outputs/output_compiled_question_set.csv',1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../inputs/compiled_question_set _edited.csv', encoding='utf-8')\n",
    "\n",
    "questions = df['question']\n",
    "comments = df['comment']\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "# df_out['question'] = questions[:len(response)]\n",
    "for i in range(1):\n",
    "    df_out[f'response_{i+1}'] = response[i]\n",
    "    \n",
    "df_out.to_csv('../outputs/output_compiled_question_set.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, Florida, Georgia, Hawaii,\n",
      "Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming, International, Federal\n"
     ]
    }
   ],
   "source": [
    "res = get_required_states(\"Are there any efforts or discussions underway at the federal level to standardize or streamline state cybersecurity regulations, and what implications could this have for state-level cybersecurity governance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas, Oklahoma, Arkansas, Louisiana, New Mexico\n"
     ]
    }
   ],
   "source": [
    "res = get_required_states(\"According to neighbouring staes of Texas legislation, who is primarily liable in the event of a breach of access regarding a rider's driver history while using services from autonomous vehicle systems?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Response for an Individual Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Getting response for: Indiana ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Kansas ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Florida ---------------\n",
      "Included.\n",
      "---------- Getting response for: Louisiana ---------------\n",
      "Included.\n",
      "---------- Getting response for: North Carolina ---------------\n",
      "Included.\n",
      "---------- Getting response for: Nebraska ---------------\n",
      "Included.\n",
      "---------- Getting response for: Utah ---------------\n",
      "Included.\n",
      "---------- Getting response for: Arizona ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Missouri ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New Mexico ---------------\n",
      "Included.\n",
      "---------- Getting response for: Delaware ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Colorado ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: South Dakota ---------------\n",
      "Included.\n",
      "---------- Getting response for: Kentucky ---------------\n",
      "Included.\n",
      "---------- Getting response for: West Virginia ---------------\n",
      "Included.\n",
      "---------- Getting response for: Alaska ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Michigan ---------------\n",
      "Included.\n",
      "---------- Getting response for: Pennsylvania ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Rhode Island ---------------\n",
      "Included.\n",
      "---------- Getting response for: Idaho ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Connecticut ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Oregon ---------------\n",
      "Included.\n",
      "---------- Getting response for: New York ---------------\n",
      "Included.\n",
      "---------- Getting response for: Oklahoma ---------------\n",
      "Included.\n",
      "---------- Getting response for: Virginia ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Massachusetts ---------------\n",
      "Included.\n",
      "---------- Getting response for: Iowa ---------------\n",
      "Included.\n",
      "---------- Getting response for: South Carolina ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Alabama ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Maine ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: California ---------------\n",
      "Included.\n",
      "---------- Getting response for: Arkansas ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Wyoming ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New Jersey ---------------\n",
      "Included.\n",
      "---------- Getting response for: Texas ---------------\n",
      "Included.\n",
      "---------- Getting response for: Wisconsin ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Mississippi ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Washington ---------------\n",
      "Included.\n",
      "---------- Getting response for: Minnesota ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New Hampshire ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Ohio ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Nevada ---------------\n",
      "Included.\n",
      "---------- Getting response for: Maryland ---------------\n",
      "Included.\n",
      "---------- Getting response for: North Dakota ---------------\n",
      "Included.\n",
      "---------- Getting response for: Illinois ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Tennessee ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Montana ---------------\n",
      "Included.\n",
      "---------- Getting response for: Georgia ---------------\n",
      "Included.\n",
      "---------- Getting response for: Vermont ---------------\n",
      "Included.\n",
      "---------- Getting response for: Hawaii ---------------\n",
      "Included.\n",
      "--- Accumulating Response ----\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "question = \"How do most states define critical infrastructure in the context of cybersecurity?\"\n",
    "\n",
    "res = get_response(question).replace('<br>','\\n')\n",
    "file = open(\"response.txt\",'w')\n",
    "file.write(\"Question: \"+ question+\"\\n\\n\")\n",
    "file.write(\"Response:\\n\")\n",
    "file.write(res)\n",
    "file.close()\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Getting response for: Montana ---------------\n",
      "Included.\n",
      "---------- Getting response for: Michigan ---------------\n",
      "Included.\n",
      "---------- Getting response for: Arizona ---------------\n",
      "Included.\n",
      "---------- Getting response for: Oregon ---------------\n",
      "Included.\n",
      "---------- Getting response for: Kentucky ---------------\n",
      "Included.\n",
      "---------- Getting response for: Washington ---------------\n",
      "Included.\n",
      "---------- Getting response for: Louisiana ---------------\n",
      "Included.\n",
      "---------- Getting response for: Ohio ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Colorado ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New Mexico ---------------\n",
      "Included.\n",
      "---------- Getting response for: Kansas ---------------\n",
      "Included.\n",
      "---------- Getting response for: Illinois ---------------\n",
      "Included.\n",
      "---------- Getting response for: Alaska ---------------\n",
      "Included.\n",
      "---------- Getting response for: Idaho ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: West Virginia ---------------\n",
      "Included.\n",
      "---------- Getting response for: Oklahoma ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Wisconsin ---------------\n",
      "Included.\n",
      "---------- Getting response for: Vermont ---------------\n",
      "Included.\n",
      "---------- Getting response for: Iowa ---------------\n",
      "Included.\n",
      "---------- Getting response for: Rhode Island ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Delaware ---------------\n",
      "Included.\n",
      "---------- Getting response for: South Dakota ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Florida ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Alabama ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Minnesota ---------------\n",
      "Included.\n",
      "---------- Getting response for: Maine ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New York ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Arkansas ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Texas ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Virginia ---------------\n",
      "Included.\n",
      "---------- Getting response for: Indiana ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Tennessee ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Utah ---------------\n",
      "Included.\n",
      "---------- Getting response for: Maryland ---------------\n",
      "Included.\n",
      "---------- Getting response for: South Carolina ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Connecticut ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Mississippi ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: North Carolina ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: North Dakota ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: New Hampshire ---------------\n",
      "Included.\n",
      "---------- Getting response for: Nevada ---------------\n",
      "Included.\n",
      "---------- Getting response for: California ---------------\n",
      "Included.\n",
      "---------- Getting response for: Pennsylvania ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Wyoming ---------------\n",
      "Included.\n",
      "---------- Getting response for: Massachusetts ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Georgia ---------------\n",
      "Included.\n",
      "---------- Getting response for: New Jersey ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Hawaii ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Nebraska ---------------\n",
      "Skipped!\n",
      "---------- Getting response for: Missouri ---------------\n",
      "Included.\n",
      "--- Accumulating Response ----\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the policies for traffic lights in all states?\"\n",
    "\n",
    "res = get_response(question,model=\"gpt-3.5-turbo\").replace('<br>','\\n')\n",
    "file = open(\"response.txt\",'w')\n",
    "file.write(\"Question: \"+ question+\"\\n\\n\")\n",
    "file.write(\"Response:\\n\")\n",
    "file.write(res)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
