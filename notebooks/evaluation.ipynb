{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH = '../inputs/qa_trayce_ground_truth.csv'\n",
    "MODEL_RESPONSES = 'C:/Users/User/Box/UTD/PhD Research/My Papers/AAAI 2024/Evaluation/batch_responses_all_baselines 1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.7777777777777778, recall=0.7777777777777778, fmeasure=0.7777777777777778), 'rouge2': Score(precision=0.5, recall=0.5, fmeasure=0.5), 'rougeL': Score(precision=0.7777777777777778, recall=0.7777777777777778, fmeasure=0.7777777777777778)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge_scores(reference_text, generated_text):\n",
    "    # Create a ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Calculate the ROUGE scores\n",
    "    scores = scorer.score(reference_text, generated_text)\n",
    "    \n",
    "    # Return the scores\n",
    "    return scores\n",
    "\n",
    "# Example usage\n",
    "reference = \"The quick brown fox jumps over the lazy dog.\"\n",
    "generated = \"The fast brown fox leaps over the lazy dog.\"\n",
    "\n",
    "rouge_scores = calculate_rouge_scores(reference, generated)\n",
    "print(rouge_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print(rouge_scores['rouge1'].precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rouge_score(gt_csv, mr_csv, score_csv):\n",
    "    df1 = pd.read_csv(gt_csv)\n",
    "    df2 = pd.read_csv(mr_csv)\n",
    "\n",
    "    rouge1_scores_p = []\n",
    "    rouge1_scores_r = []\n",
    "    rouge1_scores_f = []\n",
    "    rouge2_scores_p = []\n",
    "    rouge2_scores_r = []\n",
    "    rouge2_scores_f = []\n",
    "    rougeL_scores_p = []\n",
    "    rougeL_scores_r = []\n",
    "    rougeL_scores_f = []\n",
    "\n",
    "    answers = df1['answer']\n",
    "    # Loop through each question in df2\n",
    "    for j, ques in enumerate(df2['question']):\n",
    "        # Loop through the first 10 answers for each question\n",
    "        r1p=[]\n",
    "        r1r=[]\n",
    "        r1f=[]\n",
    "        r2p=[]\n",
    "        r2r=[]\n",
    "        r2f=[]\n",
    "        rlp=[]\n",
    "        rlr=[]\n",
    "        rlf=[]\n",
    "        for i in range(10):\n",
    "            column_name = f'response{i+1}'\n",
    "            \n",
    "            if column_name in df2.columns:\n",
    "                response = df2.loc[j, column_name]\n",
    "                # print(response)\n",
    "                rouge_scores = calculate_rouge_scores(answers[j], response)\n",
    "                r1p += [rouge_scores['rouge1'].precision]\n",
    "                r1r += [rouge_scores['rouge1'].recall]\n",
    "                r1f += [rouge_scores['rouge1'].fmeasure]\n",
    "                \n",
    "                r2p += [rouge_scores['rouge2'].precision]\n",
    "                r2r += [rouge_scores['rouge2'].recall]\n",
    "                r2f += [rouge_scores['rouge2'].fmeasure]\n",
    "\n",
    "                rlp += [rouge_scores['rougeL'].precision]\n",
    "                rlr += [rouge_scores['rougeL'].recall]\n",
    "                rlf += [rouge_scores['rougeL'].fmeasure]\n",
    "\n",
    "            else:\n",
    "                print(f\"Column {column_name} does not exist.\")\n",
    "            # print('---------')\n",
    "        # print('####################')\n",
    "        rouge1_scores_r.append(r1r)\n",
    "        rouge1_scores_f.append(r1f)\n",
    "        rouge1_scores_p.append(r1p)\n",
    "        rouge2_scores_p.append(r2p)\n",
    "        rouge2_scores_r.append(r2r)\n",
    "        rouge2_scores_f.append(r2f)\n",
    "        rougeL_scores_p.append(rlp)\n",
    "        rougeL_scores_r.append(rlr)\n",
    "        rougeL_scores_f.append(rlf)\n",
    "\n",
    "    # score_df = pd.DataFrame()\n",
    "    # score_df['question'] = df1['question']\n",
    "    # score_df['rouge1_precision'] = rouge1_scores_p\n",
    "    # score_df['rouge1_recall'] = rouge1_scores_r\n",
    "    # score_df['rouge1_fmeasure'] = rouge1_scores_f\n",
    "    # score_df['rouge2_precision'] = rouge2_scores_p\n",
    "    # score_df['rouge2_recall'] = rouge2_scores_r\n",
    "    # score_df['rouge2_fmeasure'] = rouge2_scores_f\n",
    "    # score_df['rougeL_precision'] = rougeL_scores_p\n",
    "    # score_df['rougeL_recall'] = rougeL_scores_r\n",
    "    # score_df['rougeL_fmeasure'] = rougeL_scores_f\n",
    "\n",
    "    score_df= pd.DataFrame(rouge1_scores_f)\n",
    "    score_df.to_csv('1'+score_csv)\n",
    "\n",
    "    score_df= pd.DataFrame(rouge2_scores_f)\n",
    "    score_df.to_csv('2'+score_csv)\n",
    "\n",
    "    score_df= pd.DataFrame(rougeL_scores_f)\n",
    "    score_df.to_csv('L'+score_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rouge_score_base_line(gt_csv, mr_csv, score_csv):\n",
    "    df1 = pd.read_csv(gt_csv)\n",
    "    df2 = pd.read_csv(mr_csv)\n",
    "\n",
    "    rouge1_scores_p = []\n",
    "    rouge1_scores_r = []\n",
    "    rouge1_scores_f = []\n",
    "    rouge2_scores_p = []\n",
    "    rouge2_scores_r = []\n",
    "    rouge2_scores_f = []\n",
    "    rougeL_scores_p = []\n",
    "    rougeL_scores_r = []\n",
    "    rougeL_scores_f = []\n",
    "\n",
    "    answers = df1['answer']\n",
    "    # Loop through each question in df2\n",
    "    for j, ques in enumerate(df2['question']):\n",
    "        # Loop through the first 10 answers for each question\n",
    "        r1p=0\n",
    "        r1r=0\n",
    "        r1f=0\n",
    "        r2p=0\n",
    "        r2r=0\n",
    "        r2f=0\n",
    "        rlp=0\n",
    "        rlr=0\n",
    "        rlf=0\n",
    "        for i in range(1):\n",
    "            column_name = f'answer'\n",
    "            \n",
    "            if column_name in df2.columns:\n",
    "                response = df2.loc[j, column_name]\n",
    "                # print(response)\n",
    "                rouge_scores = calculate_rouge_scores(answers[j], response)\n",
    "                r1p += rouge_scores['rouge1'].precision\n",
    "                r1r += rouge_scores['rouge1'].recall\n",
    "                r1f += rouge_scores['rouge1'].fmeasure\n",
    "\n",
    "                r2p += rouge_scores['rouge2'].precision\n",
    "                r2r += rouge_scores['rouge2'].recall\n",
    "                r2f += rouge_scores['rouge2'].fmeasure\n",
    "\n",
    "                rlp += rouge_scores['rougeL'].precision\n",
    "                rlr += rouge_scores['rougeL'].recall\n",
    "                rlf += rouge_scores['rougeL'].fmeasure\n",
    "\n",
    "            else:\n",
    "                print(f\"Column {column_name} does not exist.\")\n",
    "            # print('---------')\n",
    "        # print('####################')\n",
    "        rouge1_scores_p.append(r1p/1)\n",
    "        rouge1_scores_r.append(r1r/1)\n",
    "        rouge1_scores_f.append(r1f/1)\n",
    "        rouge2_scores_p.append(r2p/1)\n",
    "        rouge2_scores_r.append(r2r/1)\n",
    "        rouge2_scores_f.append(r2f/1)\n",
    "        rougeL_scores_p.append(rlp/1)\n",
    "        rougeL_scores_r.append(rlr/1)\n",
    "        rougeL_scores_f.append(rlf/1)\n",
    "\n",
    "    score_df = pd.DataFrame()\n",
    "    score_df['question'] = df1['question']\n",
    "    score_df['rouge1_precision'] = rouge1_scores_p\n",
    "    score_df['rouge1_recall'] = rouge1_scores_r\n",
    "    score_df['rouge1_fmeasure'] = rouge1_scores_f\n",
    "    score_df['rouge2_precision'] = rouge2_scores_p\n",
    "    score_df['rouge2_recall'] = rouge2_scores_r\n",
    "    score_df['rouge2_fmeasure'] = rouge2_scores_f\n",
    "    score_df['rougeL_precision'] = rougeL_scores_p\n",
    "    score_df['rougeL_recall'] = rougeL_scores_r\n",
    "    score_df['rougeL_fmeasure'] = rougeL_scores_f\n",
    "\n",
    "    score_df.to_csv(score_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score(gt_csv=GROUND_TRUTH, mr_csv= MODEL_RESPONSES, score_csv=\"rouge_scores_gpt_3_5.csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score_base_line(gt_csv=GROUND_TRUTH, mr_csv= '../outputs/qa_Trayce_gpt4o_responses.csv', score_csv=\"rouge_scores_10_questions_gpt4o_new.csv\")\n",
    "# rouge_score_base_line(gt_csv=GROUND_TRUTH, mr_csv= '../outputs/qa_Trayce_claude_responses.csv', score_csv=\"rouge_scores_10_questions_claud.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.10.0+cpu (from versions: 2.0.0, 2.0.0+cpu, 2.0.0+cu117, 2.0.0+cu118, 2.0.1, 2.0.1+cpu, 2.0.1+cu117, 2.0.1+cu118, 2.1.0, 2.1.0+cpu, 2.1.0+cu118, 2.1.0+cu121, 2.1.1, 2.1.1+cpu, 2.1.1+cu118, 2.1.1+cu121, 2.1.2, 2.1.2+cpu, 2.1.2+cu118, 2.1.2+cu121, 2.2.0, 2.2.0+cpu, 2.2.0+cu118, 2.2.0+cu121, 2.2.1, 2.2.1+cpu, 2.2.1+cu118, 2.2.1+cu121, 2.2.2, 2.2.2+cpu, 2.2.2+cu118, 2.2.2+cu121, 2.3.0, 2.3.0+cpu, 2.3.0+cu118, 2.3.0+cu121, 2.3.1, 2.3.1+cpu, 2.3.1+cu118, 2.3.1+cu121)\n",
      "ERROR: No matching distribution found for torch==1.10.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\__init__.py:33\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     27\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     ContextManagers,\n\u001b[0;32m     35\u001b[0m     ExplicitEnum,\n\u001b[0;32m     36\u001b[0m     ModelOutput,\n\u001b[0;32m     37\u001b[0m     PaddingStrategy,\n\u001b[0;32m     38\u001b[0m     TensorType,\n\u001b[0;32m     39\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     40\u001b[0m     cached_property,\n\u001b[0;32m     41\u001b[0m     can_return_loss,\n\u001b[0;32m     42\u001b[0m     expand_dims,\n\u001b[0;32m     43\u001b[0m     find_labels,\n\u001b[0;32m     44\u001b[0m     flatten_dict,\n\u001b[0;32m     45\u001b[0m     infer_framework,\n\u001b[0;32m     46\u001b[0m     is_jax_tensor,\n\u001b[0;32m     47\u001b[0m     is_numpy_array,\n\u001b[0;32m     48\u001b[0m     is_tensor,\n\u001b[0;32m     49\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     50\u001b[0m     is_tf_tensor,\n\u001b[0;32m     51\u001b[0m     is_torch_device,\n\u001b[0;32m     52\u001b[0m     is_torch_dtype,\n\u001b[0;32m     53\u001b[0m     is_torch_tensor,\n\u001b[0;32m     54\u001b[0m     reshape,\n\u001b[0;32m     55\u001b[0m     squeeze,\n\u001b[0;32m     56\u001b[0m     strtobool,\n\u001b[0;32m     57\u001b[0m     tensor_size,\n\u001b[0;32m     58\u001b[0m     to_numpy,\n\u001b[0;32m     59\u001b[0m     to_py_obj,\n\u001b[0;32m     60\u001b[0m     transpose,\n\u001b[0;32m     61\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     65\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     94\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[0;32m     95\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m     torch_only_method,\n\u001b[0;32m    205\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:465\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Get embeddings\n",
    "\n",
    "# Example using BERT-based similarity model\n",
    "similarity_pipeline = pipeline(\"feature-extraction\", model=\"bert-base-uncased\")\n",
    "\n",
    "response1 = \"Accessing and altering, damaging, or destroying any computer, computer system, or computer network; altering, damaging, deleting, or destroying computer programs or data; disclosing, using, controlling, or taking computer programs, data, or supporting documentation residing in, or existing internal or external to a computer, computer system, or network; directly or indirectly introducing a computer contaminator or a virus into any computer, computer system, or network; disrupting or causing the disruption of a computer, computer system, or network services or denying or causing the denial of computer or network services to any authorized user of a computer, computer system, or network; preventing a computer user from exiting a site, computer system, or network-connected location in order to compel the user’s computer to continue communicating with, connecting to, or displaying the content of the service, site, or system; obtaining any information that is required by law to be kept confidential or any records that are not public records by accessing any computer, computer system, or network that is operated by the state, a political subdivision of the state, or a medical institution; giving a password, identifying code, personal identification number, debit card number, bank account number, or other confidential information about a computer security system to another person without the consent of the person using the computer security system to restrict access to a computer, computer network, computer system, or data.\"\n",
    "response2 = '''A person who acts without authority or who exceeds authorization of use commits the crime\n",
    "of computer tampering by knowingly:\n",
    "(1) Accessing and altering, damaging, or destroying any computer, computer system, or\n",
    "computer network.\n",
    "(2) Altering, damaging, deleting, or destroying computer programs or data.\n",
    "(3) Disclosing, using, controlling, or taking computer programs, data, or supporting\n",
    "documentation residing in, or existing internal or external to, a computer, computer system, or\n",
    "network.\n",
    "(4) Directly or indirectly introducing a computer contaminator or a virus into any computer,\n",
    "computer system, or network.\n",
    "(5) Disrupting or causing the disruption of a computer, computer system, or network services\n",
    "or denying or causing the denial of computer or network services to any authorized user of a\n",
    "computer, computer system, or network.\n",
    "(6) Preventing a computer user from exiting a site, computer system, or network-connected\n",
    "location in order to compel the user’s computer to continue communicating with, connecting\n",
    "to, or displaying the content of the service, site, or system.\n",
    "(7) Obtaining any information that is required by law to be kept confidential or any records\n",
    "that are not public records by accessing any computer, computer system, or network that is\n",
    "operated by this state, a political subdivision of this state, or a medical institution.\n",
    "(8) Giving a password, identifying code, personal identification number, debit card number,\n",
    "bank account number, or other confidential information about a computer security system to\n",
    "another person without the consent of the person using the computer security system to restrict\n",
    "access to a computer, computer network, computer system, or data.'''\n",
    "\n",
    "\n",
    "embedding1 = similarity_pipeline(response1)\n",
    "embedding2 = similarity_pipeline(response2)\n",
    "\n",
    "# Convert embeddings to numpy arrays and average over the token dimension\n",
    "embedding1 = np.mean(embedding1[0], axis=0)\n",
    "embedding2 = np.mean(embedding2[0], axis=0)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "print(f\"Cosine Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Define your input texts\n",
    "text1 = \"Your first text here\"\n",
    "text2 = \"Your second text here\"\n",
    "\n",
    "# List of models to compare\n",
    "models_to_compare = [\n",
    "    \"openai-gpt\",  # OpenAI GPT\n",
    "    \"bert-base-uncased\",  # BERT base uncased\n",
    "    \"microsoft/all-minilm-v6.0.0\"  # MiniLM v6\n",
    "]\n",
    "\n",
    "# Load tokenizer and model for each model\n",
    "tokenizers = {}\n",
    "models = {}\n",
    "for model_name in models_to_compare:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizers[model_name] = tokenizer\n",
    "    models[model_name] = model\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).squeeze(0)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = {}\n",
    "for model_name, model in models.items():\n",
    "    tokenizer = tokenizers[model_name]\n",
    "    embeddings1 = get_embeddings(text1, tokenizer, model)\n",
    "    embeddings2 = get_embeddings(text2, tokenizer, model)\n",
    "    similarity_score = 1 - cosine(embeddings1, embeddings2)\n",
    "    similarities[model_name] = similarity_score\n",
    "\n",
    "# Print results\n",
    "for model_name, similarity_score in similarities.items():\n",
    "    print(f\"Cosine Similarity Score for {model_name}: {similarity_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
